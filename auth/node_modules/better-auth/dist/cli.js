#!/usr/bin/env node

// src/cli/index.ts
import { Command as Command3 } from "commander";
import "dotenv/config";

// src/cli/commands/migrate.ts
import { Command } from "commander";

// src/cli/get-config.ts
import { loadConfig } from "c12";

// src/utils/logger.ts
import { createConsola } from "consola";
var consola = createConsola({
  formatOptions: {
    date: false,
    colors: true,
    compact: true
  },
  defaults: {
    tag: "Better Auth"
  }
});
var createLogger = (options) => {
  return {
    log: (...args) => {
      !options?.disabled && consola.log("", ...args);
    },
    error: (...args) => {
      !options?.disabled && consola.error("", ...args);
    },
    warn: (...args) => {
      !options?.disabled && consola.warn("", ...args);
    },
    info: (...args) => {
      !options?.disabled && consola.info("", ...args);
    },
    debug: (...args) => {
      !options?.disabled && consola.debug("", ...args);
    },
    box: (...args) => {
      !options?.disabled && consola.box("", ...args);
    },
    success: (...args) => {
      !options?.disabled && consola.success("", ...args);
    },
    break: (...args) => {
      !options?.disabled && console.log("\n");
    }
  };
};
var logger = createLogger();

// src/cli/get-config.ts
import path from "path";
import babelPresetTypescript from "@babel/preset-typescript";
import babelPresetReact from "@babel/preset-react";
import fs from "fs";

// src/error/better-auth-error.ts
var BetterAuthError = class extends Error {
  constructor(message, cause) {
    super(message);
    this.name = "BetterAuthError";
    this.message = message;
    this.cause = cause;
    this.stack = "";
  }
};

// src/cli/get-config.ts
var possiblePaths = ["auth.ts", "auth.tsx"];
possiblePaths = [
  ...possiblePaths,
  ...possiblePaths.map((it) => `lib/${it}`),
  ...possiblePaths.map((it) => `utils/${it}`)
];
possiblePaths = [
  ...possiblePaths,
  ...possiblePaths.map((it) => `src/${it}`),
  ...possiblePaths.map((it) => `app/${it}`)
];
function stripJsonComments(jsonString) {
  return jsonString.replace(
    /\\"|"(?:\\"|[^"])*"|(\/\/.*|\/\*[\s\S]*?\*\/)/g,
    (m, g) => g ? "" : m
  );
}
function getPathAliases(cwd) {
  const tsConfigPath = path.join(cwd, "tsconfig.json");
  if (!fs.existsSync(tsConfigPath)) {
    logger.warn("[#better-auth]: tsconfig.json not found.");
    return null;
  }
  try {
    const tsConfigContent = fs.readFileSync(tsConfigPath, "utf8");
    const strippedTsConfigContent = stripJsonComments(tsConfigContent);
    const tsConfig = JSON.parse(strippedTsConfigContent);
    const { paths = {} } = tsConfig.compilerOptions || {};
    const result = {};
    const obj = Object.entries(paths);
    for (const [alias, aliasPaths] of obj) {
      for (const _ of aliasPaths) {
        result[alias[0]] = "../";
      }
    }
    return result;
  } catch (error) {
    throw new BetterAuthError("Error parsing tsconfig.json");
  }
}
var jitiOptions = (cwd) => {
  const alias = getPathAliases(cwd) || {};
  return {
    transformOptions: {
      babel: {
        presets: [
          [
            babelPresetTypescript,
            {
              isTSX: true,
              allExtensions: true
            }
          ],
          [babelPresetReact, { runtime: "automatic" }]
        ]
      }
    },
    extensions: [".ts", ".tsx", ".js", ".jsx"],
    alias
  };
};
async function getConfig({
  cwd,
  configPath
}) {
  try {
    let configFile = null;
    if (configPath) {
      const alias = getPathAliases(cwd);
      const { config } = await loadConfig({
        configFile: path.join(cwd, configPath),
        dotenv: true,
        jitiOptions: jitiOptions(cwd)
      });
      if (!config.auth && !config.default) {
        logger.error(
          "[#better-auth]: Couldn't read your auth config. Make sure to default export your auth instance or to export as a variable named auth."
        );
        process.exit(1);
      }
      configFile = config.auth?.options || config.default?.options || null;
    }
    if (!configFile) {
      for (const possiblePath of possiblePaths) {
        try {
          const { config } = await loadConfig({
            configFile: possiblePath,
            jitiOptions: jitiOptions(cwd)
          });
          const hasConfig = Object.keys(config).length > 0;
          if (hasConfig) {
            configFile = config.auth?.options || config.default?.options || null;
            if (!configFile) {
              logger.error("[#better-auth]: Couldn't read your auth config.");
              logger.break();
              logger.info(
                "[#better-auth]: Make sure to default export your auth instance or to export as a variable named auth."
              );
              process.exit(1);
            }
            break;
          }
        } catch (e) {
          logger.error("[#better-auth]: Couldn't read your auth config.", e);
          process.exit(1);
        }
      }
    }
    return configFile;
  } catch (e) {
    logger.error("Couldn't read your auth config.");
    process.exit(1);
  }
}

// src/cli/commands/migrate.ts
import { z } from "zod";
import { existsSync } from "fs";
import path2 from "path";

// src/adapters/kysely-adapter/dialect.ts
import { Kysely } from "kysely";
import {
  MysqlDialect,
  PostgresDialect,
  SqliteDialect
} from "kysely";
var createKyselyAdapter = async (config) => {
  const db = config.database;
  let dialect = void 0;
  let databaseType = "sqlite";
  if ("createDriver" in db) {
    dialect = db;
    if (dialect instanceof SqliteDialect) {
      databaseType = "sqlite";
    }
    if (dialect instanceof MysqlDialect) {
      databaseType = "mysql";
    }
    if (dialect instanceof PostgresDialect) {
      databaseType = "postgres";
    }
  }
  if ("aggregate" in db) {
    dialect = new SqliteDialect({
      database: db
    });
    databaseType = "sqlite";
  }
  if ("getConnection" in db) {
    dialect = new MysqlDialect({
      pool: db
    });
    databaseType = "mysql";
  }
  if ("connect" in db) {
    dialect = new PostgresDialect({
      pool: db
    });
    databaseType = "postgres";
  }
  return {
    kysely: dialect ? new Kysely({ dialect }) : null,
    dialect,
    databaseType
  };
};

// src/cli/commands/migrate.ts
import ora from "ora";
import chalk from "chalk";
import prompts from "prompts";

// src/cli/utils/get-migration.ts
import "kysely";

// src/db/get-tables.ts
var getAuthTables = (options) => {
  const pluginSchema = options.plugins?.reduce(
    (acc, plugin) => {
      const schema = plugin.schema;
      if (!schema) return acc;
      for (const [key, value] of Object.entries(schema)) {
        acc[key] = {
          fields: {
            ...acc[key]?.fields,
            ...value.fields
          },
          tableName: key
        };
      }
      return acc;
    },
    {}
  );
  const shouldAddRateLimitTable = options.rateLimit?.storage === "database";
  const rateLimitTable = {
    rateLimit: {
      tableName: options.rateLimit?.tableName || "rateLimit",
      fields: {
        key: {
          type: "string"
        },
        count: {
          type: "number"
        },
        lastRequest: {
          type: "number"
        }
      }
    }
  };
  const { user, session, account, ...pluginTables } = pluginSchema || {};
  const accountFields = options.account?.fields;
  const userFields = options.user?.fields;
  return {
    user: {
      tableName: options.user?.modelName || "user",
      fields: {
        [userFields?.name || "name"]: {
          type: "string",
          required: true
        },
        email: {
          type: "string",
          unique: true,
          required: true
        },
        emailVerified: {
          type: "boolean",
          defaultValue: () => false,
          required: true
        },
        image: {
          type: "string",
          required: false
        },
        createdAt: {
          type: "date",
          defaultValue: () => /* @__PURE__ */ new Date(),
          required: true
        },
        updatedAt: {
          type: "date",
          defaultValue: () => /* @__PURE__ */ new Date(),
          required: true
        },
        ...user?.fields
      },
      order: 0
    },
    session: {
      tableName: options.session?.modelName || "session",
      fields: {
        expiresAt: {
          type: "date",
          required: true
        },
        ipAddress: {
          type: "string",
          required: false
        },
        userAgent: {
          type: "string",
          required: false
        },
        userId: {
          type: "string",
          references: {
            model: options.user?.modelName || "user",
            field: "id",
            onDelete: "cascade"
          },
          required: true
        },
        ...session?.fields
      },
      order: 1
    },
    account: {
      tableName: options.account?.modelName || "account",
      fields: {
        [accountFields?.accountId || "accountId"]: {
          type: "string",
          required: true
        },
        providerId: {
          type: "string",
          required: true
        },
        userId: {
          type: "string",
          references: {
            model: options.user?.modelName || "user",
            field: "id",
            onDelete: "cascade"
          },
          required: true
        },
        accessToken: {
          type: "string",
          required: false
        },
        refreshToken: {
          type: "string",
          required: false
        },
        idToken: {
          type: "string",
          required: false
        },
        expiresAt: {
          type: "date",
          required: false
        },
        password: {
          type: "string",
          required: false
        },
        ...account?.fields
      },
      order: 2
    },
    verification: {
      tableName: options.verification?.modelName || "verification",
      fields: {
        identifier: {
          type: "string",
          required: true
        },
        value: {
          type: "string",
          required: true
        },
        expiresAt: {
          type: "date",
          required: true
        }
      }
    },
    ...pluginTables,
    ...shouldAddRateLimitTable ? rateLimitTable : {}
  };
};

// src/cli/utils/get-schema.ts
function getSchema(config) {
  const tables = getAuthTables(config);
  let schema = {};
  for (const key in tables) {
    const table = tables[key];
    if (schema[table.tableName]) {
      schema[table.tableName].fields = {
        ...schema[table.tableName].fields,
        ...table.fields
      };
      continue;
    }
    schema[table.tableName] = {
      fields: table.fields,
      order: table.order || Infinity
    };
  }
  return schema;
}

// src/cli/utils/get-migration.ts
var postgresMap = {
  string: ["character varying", "text"],
  number: [
    "int4",
    "integer",
    "bigint",
    "smallint",
    "numeric",
    "real",
    "double precision"
  ],
  boolean: ["bool", "boolean"],
  date: ["timestamp", "date"]
};
var mysqlMap = {
  string: ["varchar", "text"],
  number: [
    "integer",
    "int",
    "bigint",
    "smallint",
    "decimal",
    "float",
    "double"
  ],
  boolean: ["boolean"],
  date: ["date", "datetime"]
};
var sqliteMap = {
  string: ["TEXT"],
  number: ["INTEGER", "REAL"],
  boolean: ["INTEGER", "BOOLEAN"],
  // 0 or 1
  date: ["DATE", "INTEGER"]
};
var map = {
  postgres: postgresMap,
  mysql: mysqlMap,
  sqlite: sqliteMap
};
function matchType(columnDataType, fieldType, dbType) {
  const types = map[dbType];
  const type = types[fieldType].map((t) => t.toLowerCase());
  const matches = type.includes(columnDataType.toLowerCase());
  return matches;
}
async function getMigrations(config) {
  const betterAuthSchema = getSchema(config);
  const { kysely: db, databaseType: dbType } = await createKyselyAdapter(config);
  if (!db || !dbType) {
    logger.error(
      "Only kysely adapter is supported for migrations. You can use `generate` command to generate the schema, if you're using a different adapter."
    );
    process.exit(1);
  }
  const tableMetadata = await db.introspection.getTables();
  const toBeCreated = [];
  const toBeAdded = [];
  for (const [key, value] of Object.entries(betterAuthSchema)) {
    const table = tableMetadata.find((t) => t.name === key);
    if (!table) {
      const tIndex = toBeCreated.findIndex((t) => t.table === key);
      const tableData = {
        table: key,
        fields: value.fields,
        order: value.order || Infinity
      };
      const insertIndex = toBeCreated.findIndex(
        (t) => (t.order || Infinity) > tableData.order
      );
      if (insertIndex === -1) {
        if (tIndex === -1) {
          toBeCreated.push(tableData);
        } else {
          toBeCreated[tIndex].fields = {
            ...toBeCreated[tIndex].fields,
            ...value.fields
          };
        }
      } else {
        toBeCreated.splice(insertIndex, 0, tableData);
      }
      continue;
    }
    let toBeAddedFields = {};
    for (const [fieldName, field] of Object.entries(value.fields)) {
      const column = table.columns.find((c) => c.name === fieldName);
      if (!column) {
        toBeAddedFields[fieldName] = field;
        continue;
      }
      if (matchType(column.dataType, field.type, dbType)) {
        continue;
      } else {
        logger.warn(
          `Field ${fieldName} in table ${key} has a different type in the database. Expected ${field.type} but got ${column.dataType}.`
        );
      }
    }
    if (Object.keys(toBeAddedFields).length > 0) {
      toBeAdded.push({
        table: key,
        fields: toBeAddedFields,
        order: value.order || Infinity
      });
    }
  }
  const migrations = [];
  function getType(type) {
    const typeMap = {
      string: "text",
      boolean: "boolean",
      number: "integer",
      date: "date"
    };
    if (dbType === "mysql" && type === "string") {
      return "varchar(255)";
    }
    return typeMap[type];
  }
  if (toBeAdded.length) {
    for (const table of toBeAdded) {
      for (const [fieldName, field] of Object.entries(table.fields)) {
        const type = getType(field.type);
        const exec = db.schema.alterTable(table.table).addColumn(fieldName, type, (col) => {
          col = field.required !== false ? col.notNull() : col;
          if (field.references) {
            col = col.references(
              `${field.references.model}.${field.references.field}`
            );
          }
          return col;
        });
        migrations.push(exec);
      }
    }
  }
  if (toBeCreated.length) {
    for (const table of toBeCreated) {
      let dbT = db.schema.createTable(table.table).addColumn("id", getType("string"), (col) => col.primaryKey());
      for (const [fieldName, field] of Object.entries(table.fields)) {
        const type = getType(field.type);
        dbT = dbT.addColumn(fieldName, type, (col) => {
          col = field.required !== false ? col.notNull() : col;
          if (field.references) {
            col = col.references(
              `${field.references.model}.${field.references.field}`
            );
          }
          if (field.unique) {
            col = col.unique();
          }
          return col;
        });
      }
      migrations.push(dbT);
    }
  }
  async function runMigrations() {
    for (const migration of migrations) {
      await migration.execute();
    }
  }
  async function compileMigrations() {
    const compiled = migrations.map((m) => m.compile().sql);
    return compiled.join(";\n\n");
  }
  return { toBeCreated, toBeAdded, runMigrations, compileMigrations };
}

// src/cli/commands/migrate.ts
var migrate = new Command("migrate").option(
  "-c, --cwd <cwd>",
  "the working directory. defaults to the current directory.",
  process.cwd()
).option(
  "--config <config>",
  "the path to the configuration file. defaults to the first configuration file found."
).option("--y", "").action(async (opts) => {
  const options = z.object({
    cwd: z.string(),
    config: z.string().optional()
  }).parse(opts);
  const cwd = path2.resolve(options.cwd);
  if (!existsSync(cwd)) {
    logger.error(`The directory "${cwd}" does not exist.`);
    process.exit(1);
  }
  const config = await getConfig({
    cwd,
    configPath: options.config
  });
  if (!config) {
    logger.error(
      "No configuration file found. Add a `auth.ts` file to your project or pass the path to the configuration file using the `--config` flag."
    );
    return;
  }
  const db = await createKyselyAdapter(config).catch((e) => {
    logger.error(e.message);
    process.exit(1);
  });
  if (!db) {
    logger.error("Invalid database configuration.");
    process.exit(1);
  }
  const spinner = ora("preparing migration...").start();
  const { toBeAdded, toBeCreated, runMigrations } = await getMigrations(config);
  if (!toBeAdded.length && !toBeCreated.length) {
    spinner.stop();
    logger.success("\u{1F680} No migrations needed.");
    process.exit(0);
  }
  spinner.stop();
  logger.info(`\u{1F511} The migration will affect the following:`);
  for (const table of [...toBeCreated, ...toBeAdded]) {
    logger.info(
      "->",
      chalk.magenta(Object.keys(table.fields).join(", ")),
      chalk.white("fields on"),
      chalk.yellow(`${table.table}`),
      chalk.white("table.")
    );
  }
  const { migrate: migrate2 } = await prompts({
    type: "confirm",
    name: "migrate",
    message: "Are you sure you want to run these migrations?",
    initial: false
  });
  if (!migrate2) {
    logger.info("Migration cancelled.");
    process.exit(0);
  }
  spinner?.start("migrating...");
  await runMigrations();
  spinner.stop();
  logger.success("\u{1F680} migration was completed successfully!");
  process.exit(0);
});

// src/cli/commands/generate.ts
import { Command as Command2 } from "commander";
import { z as z2 } from "zod";
import { existsSync as existsSync3 } from "fs";
import path4 from "path";
import ora2 from "ora";
import prompts2 from "prompts";

// src/adapters/kysely-adapter/index.ts
function convertWhere(w) {
  if (!w)
    return {
      and: null,
      or: null
    };
  const and = w?.filter((w2) => w2.connector === "AND" || !w2.connector).reduce(
    (acc, w2) => ({
      ...acc,
      [w2.field]: w2.value
    }),
    {}
  );
  const or = w?.filter((w2) => w2.connector === "OR").reduce(
    (acc, w2) => ({
      ...acc,
      [w2.field]: w2.value
    }),
    {}
  );
  return {
    and: Object.keys(and).length ? and : null,
    or: Object.keys(or).length ? or : null
  };
}
function transformTo(val, fields, transform) {
  for (const key in val) {
    if (val[key] === 0 && fields[key]?.type === "boolean" && transform?.boolean) {
      val[key] = false;
    }
    if (val[key] === 1 && fields[key]?.type === "boolean" && transform?.boolean) {
      val[key] = true;
    }
    if (fields[key]?.type === "date") {
      if (!(val[key] instanceof Date)) {
        val[key] = new Date(val[key]);
      }
    }
  }
  return val;
}
function transformFrom(val, transform) {
  for (const key in val) {
    if (typeof val[key] === "boolean" && transform?.boolean) {
      val[key] = val[key] ? 1 : 0;
    }
    if (val[key] instanceof Date) {
      val[key] = val[key].toISOString();
    }
  }
  return val;
}
var kyselyAdapter = (db, config) => {
  return {
    id: "kysely",
    async create(data) {
      let { model, data: val, select } = data;
      if (config?.transform) {
        val = transformFrom(val, config.transform);
      }
      let res = await db.insertInto(model).values(val).returningAll().executeTakeFirst();
      if (config?.transform) {
        const schema = config.transform.schema[model];
        res = schema ? transformTo(val, schema, config.transform) : res;
      }
      if (select?.length) {
        const data2 = res ? select.reduce((acc, cur) => {
          if (res?.[cur]) {
            return {
              ...acc,
              [cur]: res[cur]
            };
          }
          return acc;
        }, {}) : null;
        res = data2;
      }
      return res;
    },
    async findOne(data) {
      const { model, where, select } = data;
      const { and, or } = convertWhere(where);
      let query = db.selectFrom(model).selectAll();
      if (or) {
        query = query.where((eb) => eb.or(or));
      }
      if (and) {
        query = query.where((eb) => eb.and(and));
      }
      let res = await query.executeTakeFirst();
      if (select?.length) {
        const data2 = res ? select.reduce((acc, cur) => {
          if (res?.[cur]) {
            return {
              ...acc,
              [cur]: res[cur]
            };
          }
          return acc;
        }, {}) : null;
        res = data2;
      }
      if (config?.transform) {
        const schema = config.transform.schema[model];
        res = res && schema ? transformTo(res, schema, config.transform) : res;
        return res || null;
      }
      return res || null;
    },
    async findMany(data) {
      const { model, where } = data;
      let query = db.selectFrom(model);
      const { and, or } = convertWhere(where);
      if (and) {
        query = query.where((eb) => eb.and(and));
      }
      if (or) {
        query = query.where((eb) => eb.or(or));
      }
      const res = await query.selectAll().execute();
      if (config?.transform) {
        const schema = config.transform.schema[model];
        return schema ? res.map((v) => transformTo(v, schema, config.transform)) : res;
      }
      return res;
    },
    async update(data) {
      let { model, where, update: val } = data;
      const { and, or } = convertWhere(where);
      if (config?.transform) {
        val = transformFrom(val, config.transform);
      }
      let query = db.updateTable(model).set(val);
      if (and) {
        query = query.where((eb) => eb.and(and));
      }
      if (or) {
        query = query.where((eb) => eb.or(or));
      }
      const res = await query.returningAll().executeTakeFirst() || null;
      if (config?.transform) {
        const schema = config.transform.schema[model];
        return schema ? transformTo(res, schema, config.transform) : res;
      }
      return res;
    },
    async delete(data) {
      const { model, where } = data;
      const { and, or } = convertWhere(where);
      let query = db.deleteFrom(model);
      if (and) {
        query = query.where((eb) => eb.and(and));
      }
      if (or) {
        query = query.where((eb) => eb.or(or));
      }
      await query.execute();
    },
    async createSchema(options) {
      const { compileMigrations } = await getMigrations(options);
      const migrations = await compileMigrations();
      return {
        code: migrations,
        fileName: `./better-auth_migrations/${(/* @__PURE__ */ new Date()).toISOString()}.sql`
      };
    }
  };
};

// src/db/utils.ts
async function getAdapter(options, isCli) {
  if (!options.database) {
    throw new BetterAuthError("Database configuration is required");
  }
  if ("create" in options.database) {
    return options.database;
  }
  const { kysely, databaseType } = await createKyselyAdapter(options);
  if (!kysely) {
    throw new BetterAuthError("Failed to initialize database adapter");
  }
  const tables = getAuthTables(options);
  let schema = {};
  for (const table of Object.values(tables)) {
    schema[table.tableName] = table.fields;
  }
  return kyselyAdapter(kysely, {
    transform: {
      schema,
      date: true,
      boolean: databaseType === "sqlite"
    }
  });
}

// src/cli/commands/generate.ts
import fs3 from "fs/promises";
import chalk2 from "chalk";

// src/adapters/prisma-adapter/generate-cli.ts
import { produceSchema } from "@mrleebo/prisma-ast";
import { existsSync as existsSync2 } from "fs";
import path3 from "path";
import fs2 from "fs/promises";

// src/utils/misc.ts
function capitalizeFirstLetter(str) {
  return str.charAt(0).toUpperCase() + str.slice(1);
}

// src/adapters/prisma-adapter/generate-cli.ts
async function generatePrismaSchema({
  provider,
  options,
  file
}) {
  const tables = getAuthTables(options);
  const filePath = file || "./prisma/schema.prisma";
  const schemaPrismaExist = existsSync2(path3.join(process.cwd(), filePath));
  let schemaPrisma = "";
  if (schemaPrismaExist) {
    schemaPrisma = await fs2.readFile(
      path3.join(process.cwd(), filePath),
      "utf-8"
    );
  } else {
    schemaPrisma = getNewPrisma(provider);
  }
  const schema = produceSchema(schemaPrisma, (builder) => {
    for (const table in tables) {
      let getType2 = function(type, isOptional) {
        if (type === "string") {
          return isOptional ? "String?" : "String";
        }
        if (type === "number") {
          return isOptional ? "Int?" : "Int";
        }
        if (type === "boolean") {
          return isOptional ? "Boolean?" : "Boolean";
        }
        if (type === "date") {
          return isOptional ? "DateTime?" : "DateTime";
        }
      };
      var getType = getType2;
      const fields = tables[table].fields;
      const originalTable = tables[table].tableName;
      const tableName = capitalizeFirstLetter(originalTable);
      const prismaModel = builder.findByType("model", {
        name: tableName
      });
      !prismaModel && builder.model(tableName).field("id", "String").attribute("id");
      for (const field in fields) {
        const attr = fields[field];
        if (prismaModel) {
          const isAlreadyExist = builder.findByType("field", {
            name: field,
            within: prismaModel.properties
          });
          if (isAlreadyExist) {
            continue;
          }
        }
        builder.model(tableName).field(field, getType2(attr.type, !attr.required));
        if (attr.unique) {
          builder.model(tableName).blockAttribute(`unique([${field}])`);
        }
        if (attr.references) {
          builder.model(tableName).field(
            `${attr.references.model.toLowerCase()}s`,
            capitalizeFirstLetter(attr.references.model)
          ).attribute(
            `relation(fields: [${field}], references: [${attr.references.field}], onDelete: Cascade)`
          );
        }
      }
      const hasAttribute = builder.findByType("attribute", {
        name: "map",
        within: prismaModel?.properties
      });
      if (originalTable !== tableName && !hasAttribute) {
        builder.model(tableName).blockAttribute("map", originalTable);
      }
    }
  });
  return {
    code: schema.trim() === schemaPrisma.trim() ? "" : schema,
    fileName: filePath
  };
}
var getNewPrisma = (provider) => `generator client {
    provider = "prisma-client-js"
  }
  
  datasource db {
    provider = "${provider}"
    url      = ${provider === "sqlite" ? `"file:./dev.db"` : `env("DATABASE_URL")`}
  }`;

// src/cli/commands/generate.ts
var generate = new Command2("generate").option(
  "-c, --cwd <cwd>",
  "the working directory. defaults to the current directory.",
  process.cwd()
).option(
  "--config <config>",
  "the path to the configuration file. defaults to the first configuration file found."
).option("--output <output>", "the file to output to the generated schema").option("--y", "").action(async (opts) => {
  const options = z2.object({
    cwd: z2.string(),
    config: z2.string().optional(),
    output: z2.string().optional()
  }).parse(opts);
  const cwd = path4.resolve(options.cwd);
  if (!existsSync3(cwd)) {
    logger.error(`The directory "${cwd}" does not exist.`);
    process.exit(1);
  }
  const config = await getConfig({
    cwd,
    configPath: options.config
  });
  if (!config) {
    logger.error(
      "No configuration file found. Add a `auth.ts` file to your project or pass the path to the configuration file using the `--config` flag."
    );
    return;
  }
  const spinner = ora2("preparing schema...").start();
  const adapter = await getAdapter(config, true).catch((e) => {
    logger.error(e.message);
    process.exit(1);
  });
  let code = "";
  let fileName = "";
  let append = false;
  let overwrite = false;
  if (adapter.id === "prisma") {
    spinner.text = "generating schema...";
    const result = await generatePrismaSchema({
      options: config,
      file: options.output,
      provider: adapter.options?.provider || "pg"
    });
    code = result.code;
    fileName = result.fileName;
  } else {
    if (!adapter.createSchema) {
      logger.error("The adapter does not support schema generation.");
      process.exit(1);
    }
    const result = await adapter.createSchema(config, options.output);
    code = result.code;
    fileName = result.fileName;
    append = result.append || false;
    overwrite = result.overwrite || false;
  }
  spinner.stop();
  if (!code) {
    logger.success("Your schema is already up to date.");
    process.exit(0);
  }
  if (append || overwrite) {
    const { confirm: confirm2 } = await prompts2({
      type: "confirm",
      name: "confirm",
      message: `The file ${fileName} already exists. Do you want to ${chalk2.yellow(
        `${overwrite ? "overwrite" : "append"}`
      )} the schema to the file?`
    });
    if (confirm2) {
      const exist = existsSync3(path4.join(cwd, fileName));
      if (!exist) {
        await fs3.mkdir(path4.dirname(path4.join(cwd, fileName)), {
          recursive: true
        });
      }
      if (overwrite) {
        await fs3.writeFile(path4.join(cwd, fileName), code);
      } else {
        await fs3.appendFile(path4.join(cwd, fileName), code);
      }
      logger.success(`\u{1F680} schema was appended successfully!`);
      process.exit(0);
    } else {
      logger.error("Schema generation aborted.");
      process.exit(1);
    }
  }
  const { confirm } = await prompts2({
    type: "confirm",
    name: "confirm",
    message: `Do you want to generate the schema to ${chalk2.yellow(
      fileName
    )}?`
  });
  if (!confirm) {
    logger.error("Schema generation aborted.");
    process.exit(1);
  }
  if (!options.output) {
    const dirExist = existsSync3(path4.dirname(path4.join(cwd, fileName)));
    if (!dirExist) {
      await fs3.mkdir(path4.dirname(path4.join(cwd, fileName)), {
        recursive: true
      });
    }
  }
  await fs3.writeFile(options.output || path4.join(cwd, fileName), code);
  logger.success(`\u{1F680} schema was generated successfully!`);
  process.exit(0);
});

// src/cli/index.ts
async function main() {
  const program = new Command3().name("better-auth");
  program.addCommand(migrate).addCommand(generate).version("0.0.1").description("Better Auth CLI");
  program.parse();
}
main();
